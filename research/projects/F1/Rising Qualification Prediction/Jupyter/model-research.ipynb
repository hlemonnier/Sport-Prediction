{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment: Rising Qualification Prediction Research\n",
        "\n",
        "Objective:\n",
        "- Compare candidate models for predicting Q3 delta (qualifying) and race position using FP data.\n",
        "- Success criteria: lower MAE on target, higher Spearman rank correlation, and better top-10 hit rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Setup: imports and reproducibility\n",
        "from __future__ import annotations\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "SEED = 7\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "PROJECT_ROOT = pathlib.Path('..').resolve()\n",
        "PYTHON_DIR = PROJECT_ROOT / 'Python'\n",
        "if str(PYTHON_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(PYTHON_DIR))\n",
        "\n",
        "from rqp.data import build_training_data\n",
        "from rqp.prediction import predict_with_model\n",
        "from rqp.providers import FastF1Provider, OpenF1Provider\n",
        "from rqp.training import train_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plan\n",
        "\n",
        "- Hypothesis: FP deltas and ranks are sufficient early in the season.\n",
        "- Variables to sweep: model type, feature set, and training seasons.\n",
        "- Metrics to record: MAE, Spearman rank correlation, top-10 hit rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Experiment configuration\n",
        "CONFIG = {\n",
        "    'source': 'fastf1',  # or 'openf1'\n",
        "    'mode': 'qualifying',  # or 'race'\n",
        "    'target_year': 2025,\n",
        "    'target_round': 1,\n",
        "    'train_seasons': [2023, 2024],\n",
        "    'include_standings': False,\n",
        "    'cache_dir': str(PROJECT_ROOT / '.cache' / 'fastf1'),\n",
        "    'meeting_name': None,  # openf1 only\n",
        "    'country_name': None,  # openf1 only\n",
        "}\n",
        "\n",
        "if CONFIG['source'] == 'fastf1':\n",
        "    provider = FastF1Provider(CONFIG['cache_dir'])\n",
        "else:\n",
        "    provider = OpenF1Provider(\n",
        "        cache_dir=CONFIG['cache_dir'],\n",
        "        target_round=CONFIG['target_round'],\n",
        "        meeting_name=CONFIG['meeting_name'],\n",
        "        country_name=CONFIG['country_name'],\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Build training dataset\n",
        "train_df, notes = build_training_data(\n",
        "    provider=provider,\n",
        "    mode=CONFIG['mode'],\n",
        "    train_seasons=CONFIG['train_seasons'],\n",
        "    target_year=CONFIG['target_year'],\n",
        "    target_round=CONFIG['target_round'],\n",
        "    include_standings=CONFIG['include_standings'],\n",
        ")\n",
        "\n",
        "notes, train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Define features + metrics\n",
        "if CONFIG['mode'] == 'qualifying':\n",
        "    feature_cols = [\n",
        "        'fp1_delta', 'fp2_delta', 'fp3_delta', 'fp_mean_delta',\n",
        "        'fp1_rank', 'fp2_rank', 'fp3_rank', 'fp_mean_rank'\n",
        "    ]\n",
        "    fallback_cols = [c for c in feature_cols if c.endswith('_delta')]\n",
        "else:\n",
        "    feature_cols = [\n",
        "        'fp1_delta', 'fp2_delta', 'fp3_delta', 'fp_mean_delta',\n",
        "        'fp1_rank', 'fp2_rank', 'fp3_rank', 'fp_mean_rank',\n",
        "        'qualy_position'\n",
        "    ]\n",
        "    if CONFIG['include_standings']:\n",
        "        feature_cols.append('position_start')\n",
        "    fallback_cols = ['qualy_position']\n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "    return float(np.mean(np.abs(np.array(y_true) - np.array(y_pred))))\n",
        "\n",
        "def spearman(y_true, y_pred):\n",
        "    return float(pd.Series(y_true).rank().corr(pd.Series(y_pred).rank()))\n",
        "\n",
        "def top10_hit_rate(df):\n",
        "    pred_rank = df['pred'].rank(method='first')\n",
        "    true_rank = df['target'].rank(method='first')\n",
        "    pred_top10 = set(df.loc[pred_rank <= 10].index)\n",
        "    true_top10 = set(df.loc[true_rank <= 10].index)\n",
        "    if not true_top10:\n",
        "        return 0.0\n",
        "    return len(pred_top10 & true_top10) / 10\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Baseline model: Ridge (via train_model)\n",
        "if train_df.empty:\n",
        "    raise ValueError('Training data is empty. Adjust seasons or source.')\n",
        "\n",
        "# Simple random split for fast iteration\n",
        "train_df = train_df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
        "split = int(len(train_df) * 0.8)\n",
        "train_part = train_df.iloc[:split]\n",
        "test_part = train_df.iloc[split:]\n",
        "\n",
        "model = train_model(train_part, feature_cols)\n",
        "test_part = test_part.copy()\n",
        "test_part['pred'] = predict_with_model(model, test_part, feature_cols, fallback_cols)\n",
        "\n",
        "metrics = {\n",
        "    'mae': mae(test_part['target'], test_part['pred']),\n",
        "    'spearman': spearman(test_part['target'], test_part['pred']),\n",
        "    'top10_hit_rate': top10_hit_rate(test_part),\n",
        "}\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results and Notes\n",
        "\n",
        "- Record the metrics from each run here.\n",
        "- Capture any surprising failures (missing data, session gaps, etc.).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "- Try alternative models (RandomForest, XGBoost) and compare metrics.\n",
        "- Add features: sector times, long-run pace, or weather signals.\n",
        "- Evaluate a time-based split (earlier rounds train, later rounds test).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}